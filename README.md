# LTDB Advanced RAG System

LTDB Database를 이용한 RAG 시스템.

*HTML 자료*를 내장하고 있다고 가정함. 형식은 LTDB Database()를 따름.

Major portion of the code is generated by AI

---


## System Architecture

### 시스템 아키텍처 (System Architecture)

본 시스템은 **데이터 적재(Ingestion)**와 **실시간 검색/생성(Runtime)** 두 가지 주요 파이프라인으로 구성됩니다.

```text
[ 데이터 적재 파이프라인 (Data Ingestion) ]
      |
      v
[ run_ingest.sh ] (총괄 스크립트)
      |
      |=== 1. 시각 정보 (Vision)
      |     |
      |     +---> [ vision_ingest.py ] --- (HTML 캡처) ---> [ Vision Data ]
      |     |
      |     +---> [ colpali_ingest.py ] -- (임베딩 생성) --> [ ColPali DB ]
      |
      |=== 2. 텍스트 정보 (Matrix RAPTOR)
            |
            +---> [ raptor_level0.py ] <=== (Util: xsampa_converter.py)
            |       | (HTML -> 텍스트/음소 변환 및 청크 추출)
            |       v
            |     [ L0_data.jsonl ]
            |
            +---> [ raptor_level1.py ]
            |       | (L0 데이터 -> 계층적 요약 수행)
            |       v
            |     [ L1_data.jsonl ]
            |
            +---> [ raptor_finalize.py ] --- (DB 적재) ---> [ Postgres (linguistics_raptor) ]


[ 런타임 파이프라인 (Runtime: Retrieval & Generation) ]
      |
      | (사용자 질문)
      v
[ src/main.py ] (Semantic Router: 의도 파악 및 라우팅)
      |
      |--- [ Intent: GRAPH ] ---> [ src/retrieval/graph_search.py ]
      |                             | (Neo4j Cypher 쿼리 실행)
      |                             v
      |                           [ Neo4j Database ]
      |
      |--- [ Intent: VECTOR ] ---> [ src/retrieval/rag_retrieve.py ]
      |                             | (하이브리드 검색: ColPali + Chroma/Postgres)
      |                             +---> [ src/retrieval/colpali_search.py ]
      |                             v
      |                           [ Retrieved Context (JSON) ]
      |
      v
[ src/llm/rag_generate.py ] (답변 생성)
      | (컨텍스트 + 프롬프트)
      v
[ LLM (Ollama: llama3, etc.) ]
      |
      v
[ 최종 답변 (Final Answer) ]
```

---

## 실행 가이드 (Execution Guide)

### 1. 환경 설정 (Environment Setup)
의존성 패키지와 데이터베이스 인프라를 실행합니다.

```bash
# 파이썬 의존성 설치
uv sync

# Neo4j 및 Postgres (RAPTOR용) 실행
sudo docker-compose up -d
```

### 2. 데이터 적재 (Data Ingestion)
검색에 필요한 인덱스를 구축합니다.

**자동화 파이프라인 (`run_ingest.sh`)**
이 스크립트는 다음 단계들을 순차적으로 수행합니다:
1.  **Vision Capture**: HTML 내용을 이미지로 캡처합니다.
2.  **Visual Indexing**: 캡처된 이미지를 ColPali 임베딩으로 변환합니다.
3.  **Matrix RAPTOR**:
    *   **Level 0**: HTML에서 텍스트 청크를 추출합니다.
    *   **Level 1**: 청크들을 요약하여 상위 계층(Summary)을 생성합니다. (순환 요약 방지 및 패턴 종합 적용됨)
    *   **Finalize**: 최종 데이터를 PostgreSQL (PGVector)에 적재합니다.

```bash
# Playwright 브라우저 설치 (최초 1회)
uv run playwright install

# 전체 파이프라인 실행
./run_ingest.sh
```

**참고 사항:**
*   `src/ingest/ingest.py`: **Deprecated**. 더 이상 사용되지 않는 구버전 스크립트입니다.
*   `src/ingest/graph_ingest.py`: **Experimental**. 지식 그래프 구축용이며 현재 파이프라인에는 포함되지 않았습니다.

### 3. Running the System
시스템을 대화형으로 시작합니다. Graph DB 연결 여부는 config에서 enable 가능합니다.

```bash
uv run src/main.py
```

**Workflow:**
1. **User Input**: 사용자가 질문을 입력합니다.
2. **Routing**: `src/main.py`가 질문을 분석하여 Graph 또는 Vector 모드로 라우팅합니다.
3. **Retrieval**:
   - **Graph Mode**: `src/retrieval/graph_search.py`가 Neo4j를 검색합니다.
   - **Vector Mode**: `src/retrieval/rag_retrieve.py`가 텍스트/이미지를 검색하고 `context.json`에 저장합니다.
4. **Generation**: `src/llm/rag_generate.py`가 검색된 컨텍스트를 기반으로 LLM을 통해 답변을 생성합니다.

---

## Configuration (`config.yaml`)

- `rag.enable_graph`: 라우터 활성화 여부 (true/false)
- `llm.model_name`: 로컬 LLM 모델 이름
- `neo4j.*`: 데이터베이스 연결 설정
